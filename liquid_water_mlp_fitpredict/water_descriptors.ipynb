{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Gradient Optimisation for Feature Selection on Water Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ase.io import read as ase_read\n",
    "\n",
    "from dadapy.feature_weighting import FeatureWeighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Large SOAP datasets and especially ACSFs are somewhat slow to calculate, so I mostly just run this on our local cluster and then load from numpy files.\n",
    "To recalculate the descriptors, use `make_descriptors.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"./data\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ase.Atoms objects for each liquid configuration\n",
    "liquid_frames = ase_read(data_dir.joinpath(\"ice_and_water_data/dataset_1000_eVAng.xyz\"), index=':')\n",
    "n_atoms = np.sum(np.asarray([len(frame) for frame in liquid_frames], dtype=np.int16))\n",
    "atom_types = np.zeros((n_atoms), dtype=np.int8)\n",
    "\n",
    "# Collect some metadata, like how many atoms/config, atoms in total and which atom is even an oxygen.\n",
    "counter = 0\n",
    "for frame in liquid_frames:\n",
    "    atom_types[counter:counter+len(frame)] = frame.get_atomic_numbers()\n",
    "    counter+=len(frame)\n",
    "is_o = atom_types==8\n",
    "is_h = np.logical_not(is_o)\n",
    "\n",
    "print(f\"Found {np.count_nonzero(is_o)} Oxygen atoms and {np.count_nonzero(is_h)} Hydrogen atoms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new descriptors from file or laod ase.Atoms objects and recalculate\n",
    "# Recalculation here works best when just getting SOAPs, ACSF takes a little long\n",
    "average_soap = np.load(data_dir.joinpath(\"water_phase_store/average_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "atomic_soap = np.load(data_dir.joinpath(\"water_phase_store/singleatom_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_soap.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_soap.shape)\n",
    "\n",
    "# The file format of the input file the descriptors are calculated from is 54 solid, 1000 liquid\n",
    "# So we can just get the liquid configurations by getting the number of atoms n_atoms in the liquid configurations\n",
    "# From the end of the decriptor matrix\n",
    "liquid_atomic_soap = atomic_soap[-n_atoms:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_acsf = np.asarray(np.load(data_dir.joinpath(\"water_phase_store/average_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "atomic_acsf = np.asarray(np.load(data_dir.joinpath(\"water_phase_store/singleatom_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "liquid_atomic_acsf = atomic_acsf[-n_atoms:, :].copy()\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_acsf.shape)\n",
    "print(\"Fetched computed liquid atomic SOAP descriptors for %u configurations and with %u features each.\"%liquid_atomic_acsf.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_acsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing of Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf]\n",
    "for desc in descriptors:\n",
    "    desc /= np.linalg.norm(desc, axis=-1)[:, np.newaxis]\n",
    "average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf = descriptors\n",
    "\n",
    "# apparently atomic acsf sometimes become nan, set to 0\n",
    "nan_frames = np.argwhere(np.isnan(atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "atomic_acsf[nan_frames, :] = 0.\n",
    "\n",
    "nan_frames = np.argwhere(np.isnan(liquid_atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in liquid atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "liquid_atomic_acsf[nan_frames, :] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Input and Target Data\n",
    "\n",
    "`target_data` is the space which delivers the target ranks, `input_space` is the space for which the gammas should be optimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "# random_selection = rng.choice(liquid_atomic_soap.shape[0], 300)\n",
    "target_data = liquid_atomic_soap[::500]\n",
    "input_space = liquid_atomic_acsf[::500]\n",
    "\n",
    "fw_input = FeatureWeighting(coordinates=input_space, maxk=input_space.shape[0]-1, verbose=True)\n",
    "fw_target = FeatureWeighting(coordinates=target_data, maxk=target_data.shape[0]-1, verbose=True)\n",
    "\n",
    "if True:\n",
    "    stds = np.std(input_space, axis=0)\n",
    "    stds[stds==0.] = 1.\n",
    "    standardised_input = input_space/stds[np.newaxis, :]\n",
    "    # dist_matrix = kimb.compute_dist_matrix(data=target_data.astype(np.double), period=np.zeros((target_data.shape[-1])))\n",
    "    # truth_ranks = stats.rankdata(dist_matrix, method='average', axis=1).astype(int, copy=False)\n",
    "\n",
    "print(f\"Working on ground truth shaped {target_data.shape} and optimising space of shape {input_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Skip this section and head to \"Evaluations and Plotting\" where you can load pre-generated descriptors and kernel imbalances used in the publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Optimal Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gammas = np.ones((input_space.shape[-1],), dtype=np.double)\n",
    "lr_list = np.logspace(-2, 2, 10)\n",
    "\n",
    "opt_l_rate = fw_input.return_optimal_learning_rate(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None, \n",
    "    n_epochs=50, decaying_lr=\"exp\", \n",
    "    n_samples=154, trial_learning_rates=lr_list,\n",
    ")\n",
    "\n",
    "kernel_imbalances_list = fw_input.history['dii_per_epoch_per_lr'][np.argwhere(opt_l_rate==lr_list)[0, 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "ax.plot(kernel_imbalances_list, label=\"kernel imbalances\")\n",
    "\n",
    "ax.set_title(\"Loss for optimal learning rate %f\"%opt_l_rate)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_ylabel('Kernel Imbalance')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimise using Lasso Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    num_nonzero_features,\n",
    "    l1_penalties_opt_per_nfeatures,\n",
    "    dii_opt_per_nfeatures, \n",
    "    weights_opt_per_nfeatures\n",
    ") = fw_input.return_lasso_optimization_dii_search(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None, \n",
    "    learning_rate=opt_l_rate, constrain=True, decaying_lr=\"exp\",\n",
    "    n_epochs=100, refine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Processing Gammas from Lasso Optimisation\n",
    "\n",
    "The weights returned by lasso optimisation are returned unordered.\n",
    "This recalculates the information imbalance for each entry and orders the weights by number of non-zero features and best information imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert order so it has least features first\n",
    "kernel_imbs = dii_opt_per_nfeatures[::-1]\n",
    "lasso_gammas = weights_opt_per_nfeatures[::-1]\n",
    "num_nonzero_features = num_nonzero_features[::-1]\n",
    "l1_penalties_opt_per_nfeatures = l1_penalties_opt_per_nfeatures[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Backwards Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_gammas, greedy_imbs = fw_input.return_backward_greedy_dii_elimination(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None,\n",
    "    initial_weights=initial_gammas, lambd=None, n_epochs=80,\n",
    "    l_rate=opt_l_rate, constrain=False, decaying_lr=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations and Plotting\n",
    "\n",
    "If no recalculations are needed just go to this part and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='load_old'\n",
    "if mode=='save_new':\n",
    "    # make a subdirectory for storing results\n",
    "    if not data_dir.joinpath('water_phase_store').exists():\n",
    "        data_dir.joinpath('water_phase_store').mkdir()\n",
    "\n",
    "    np.save(data_dir.joinpath('water_phase_store/kernel_imbs_hartbohr_lambda.npy'), kernel_imbs, allow_pickle=False)\n",
    "    np.save(data_dir.joinpath('water_phase_store/lasso_gammas_hartbohr_lambda.npy'), lasso_gammas, allow_pickle=False)\n",
    "    np.save(data_dir.joinpath(\"water_phase_store/greedy_gammas_hartbohr_lambda.npy\"), greedy_gammas, allow_pickle=False)\n",
    "    np.save(data_dir.joinpath(\"water_phase_store/greedy_imbs_hartbohr_lambda.npy\"), greedy_imbs, allow_pickle=False)\n",
    "elif mode=='load_old':\n",
    "    kernel_imbs = np.load(data_dir.joinpath('water_phase_store/kernel_imbs_hartbohr_lambda.npy'))\n",
    "    lasso_gammas = np.load(data_dir.joinpath('water_phase_store/lasso_gammas_hartbohr_lambda.npy'))\n",
    "    greedy_gammas = np.load(data_dir.joinpath(\"water_phase_store/greedy_gammas_hartbohr_lambda.npy\"))\n",
    "    greedy_imbs = np.load(data_dir.joinpath(\"water_phase_store/greedy_imbs_hartbohr_lambda.npy\"))\n",
    "\n",
    "where_gammas_found = (kernel_imbs!=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "rng = np.random.default_rng()\n",
    "batch_indices = rng.choice(liquid_atomic_soap.shape[0], size=(n_batches, input_space.shape[0]), replace=False)\n",
    "\n",
    "true_fws = []\n",
    "for batch in batch_indices:\n",
    "    true_fws.append(FeatureWeighting(\n",
    "        coordinates=liquid_atomic_soap[batch, :], maxk=len(batch)-1, verbose=False\n",
    "    ))\n",
    "\n",
    "print(\"Kernel Imbalance\")\n",
    "batched_lasso_imbalances = np.empty((len(kernel_imbs), n_batches), dtype=np.float32)\n",
    "for n_dims in range(len(kernel_imbs)):\n",
    "    if where_gammas_found[n_dims]:\n",
    "        for ii_batch, batch in enumerate(batch_indices):\n",
    "            batched_lasso_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "                coordinates=liquid_atomic_acsf[batch, :]*lasso_gammas[n_dims, :], maxk=len(batch)-1, verbose=False\n",
    "            ).return_dii(\n",
    "                target_data=true_fws[ii_batch],\n",
    "                lambd=None\n",
    "            )\n",
    "\n",
    "print(\"Greedy Imbalance\")\n",
    "batched_greedy_imbalances = np.empty((len(greedy_imbs), n_batches), dtype=np.float32)\n",
    "for n_dims in range(greedy_gammas.shape[-1]):\n",
    "    for ii_batch, batch in enumerate(batch_indices):\n",
    "        batched_greedy_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "            coordinates=liquid_atomic_acsf[batch, :]*greedy_gammas[n_dims, -1, :], \n",
    "            maxk=len(batch)-1, verbose=False,\n",
    "        ).return_dii(\n",
    "            target_data=true_fws[ii_batch],\n",
    "            lambd=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Selection\")\n",
    "batched_random_imbalances = np.empty((len(kernel_imbs), n_batches), dtype=np.float32)\n",
    "rand_gamma_mask = np.zeros((input_space.shape[-1], ), dtype=bool)\n",
    "for n_dims in range(1, len(kernel_imbs)):\n",
    "    for ii_batch, batch in enumerate(batch_indices):\n",
    "        rand_gamma_mask[:] = False\n",
    "        rand_gamma_mask[rng.choice(input_space.shape[-1], size=(n_dims, ), replace=False)] = True\n",
    "        batched_random_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "            coordinates=(liquid_atomic_acsf[batch, :]/stds)[:, rand_gamma_mask], \n",
    "            maxk=len(batch)-1, verbose=False,\n",
    "        ).return_dii(\n",
    "            target_data=true_fws[ii_batch],\n",
    "            lambd=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "where_gammas_found = (kernel_imbs!=0.)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "\n",
    "if False:\n",
    "    ax.plot(range(1, len(classic_greedy_imbalances)+1), classic_greedy_imbalances[::-1], 'x--', label='classic greedy')\n",
    "    ax.fill_between(\n",
    "        range(1, len(classic_greedy_imbalances)+1), \n",
    "        np.min(batched_classic_imbalances[::-1, :], axis=1),\n",
    "        np.max(batched_classic_imbalances[::-1, :], axis=1),\n",
    "        alpha=0.3, linewidth=10\n",
    "    )\n",
    "    ax.plot(\n",
    "    np.arange(1, greedy_select_imbalance.shape[0]+1), greedy_select_imbalance[::-1],\n",
    "    'o--', label='greedy select'\n",
    "    )\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], kernel_imbs[where_gammas_found],\n",
    "    'o--', label='lasso optimisation'\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], \n",
    "    np.min(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    np.max(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(1, greedy_imbs.shape[0]+1), greedy_imbs[::-1, -1],\n",
    "    'o--', label='greedy weighted optimisation'\n",
    ")\n",
    "ax.fill_between(\n",
    "    range(1, len(batched_greedy_imbalances)+1), \n",
    "    np.min(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    np.max(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    alpha=0.3, linewidth=10\n",
    ")\n",
    "\n",
    "ax.vlines(\n",
    "    np.arange(1, kernel_imbs.shape[0]+1), \n",
    "    np.min(batched_random_imbalances, axis=1),\n",
    "    np.max(batched_random_imbalances, axis=1),\n",
    "    alpha=0.8, color='tab:grey', linewidth=5, label='random selection'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Dimensions')\n",
    "ax.set_ylabel(r'$DII(S^{red} \\to S^{true})$')\n",
    "ax.set_title(\"Comparison of %u ACSF descriptors to %u SOAP descriptors\\nfor %u different atom environments\"%(input_space.shape[1], target_data.shape[-1], input_space.shape[0]))\n",
    "ax.legend()\n",
    "ax.set_ylim([0., 0.6])\n",
    "ax.set_xlim([1, 30])\n",
    "\n",
    "fig.savefig(\"ii_history_acsf%u_c%u.png\"%input_space.shape[::-1], format='png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Runtimes and RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "target_dir = data_dir.joinpath(\"mlp_prediction\")\n",
    "\n",
    "results_dict = {}\n",
    "for logfile in target_dir.joinpath('errorbar_logs').glob('*.log'):\n",
    "    with open(logfile, 'r') as f:\n",
    "        content = f.read()\n",
    "        # this is what the mlps were called and how they can be identified in this context\n",
    "        runtype = re.search(\"231213_pot_acsf(.*)_hartbohr_scaleunits_bcdata_lambda\", content).group(1)\n",
    "        run_num = re.search(\"run_([0-9]*)\", content).group(1)\n",
    "\n",
    "        # memory_kb = re.search(\"\\s([0-9]*)maxresident\", content).group(1)\n",
    "        runtime_s = re.search(\"user\\s0m([0-9]*\\.[0-9]*)\", content).group(1)\n",
    "        \n",
    "        pot_dir = target_dir.joinpath(\"mlps/pot_acsf\"+runtype+\"/run_\"+run_num)\n",
    "\n",
    "        all_errors = np.loadtxt(pot_dir.joinpath('learning-curve.out'))\n",
    "        all_errors[:, 1:9] *= 27.211386245988\n",
    "        all_errors[:, 9:13] *= 51.421 # Hartree/Bohr to eV/Angstrom conversion\n",
    "        rmse_ftest_evA = all_errors[-1, 12]\n",
    "        \n",
    "        if runtype not in results_dict:\n",
    "            results_dict[runtype] = {\"runtimes\": [], \"rmses\": []}\n",
    "        \n",
    "        results_dict[runtype][\"runtimes\"].append(float(runtime_s))\n",
    "        results_dict[runtype][\"rmses\"].append(rmse_ftest_evA) \n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "fontsize = 12\n",
    "\n",
    "if False:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"Helvetica\",\n",
    "        \"font.size\": fontsize,\n",
    "        'text.latex.preamble': r'\\usepackage{amsmath}'\n",
    "    })\n",
    "\n",
    "double_ax = False\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(5, 6))\n",
    "\n",
    "kernel_keys = ['10', '18', '25', '38', '50', '176']\n",
    "rand_keys = ['10rand', '18rand', '25rand', '38rand', '50rand', '176']\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "greedy_dii_color = \"#f29944\" # cmap(0.6)\n",
    "lasso_dii_color = \"#989ec1\" # cmap(0.3)\n",
    "random_dii_color = \"tab:grey\"\n",
    "\n",
    "mae_ax = axes[1]\n",
    "\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    label=r'L$_1$ reg.', color=lasso_dii_color, marker='o', linestyle='-'\n",
    ")\n",
    "mae_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.min(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    [np.max(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    alpha=0.4, color=lasso_dii_color\n",
    ")\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    label='random', color=random_dii_color, marker='^', linestyle='-.', alpha=0.8\n",
    ")\n",
    "mae_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.min(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    [np.max(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    alpha=0.2, color=random_dii_color\n",
    ")\n",
    "mae_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "mae_ax.set_ylabel(\"Test Force RMSE [eV/A]\", fontsize=fontsize)\n",
    "mae_ax.tick_params(axis='x', which='both', labelsize=fontsize)\n",
    "mae_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "mae_ax.grid(axis='y')\n",
    "mae_ax.legend(fontsize=fontsize)\n",
    "\n",
    "time_ax = axes[2]\n",
    "\n",
    "kernel_times = np.array([np.mean(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "kernel_uppers = np.array([np.max(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "kernel_lowers = np.array([np.min(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "random_times = np.array([np.mean(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "random_uppers = np.array([np.max(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "random_lowers = np.array([np.min(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "\n",
    "max_time = np.max(np.concatenate([kernel_times, random_times]))\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    kernel_times/max_time,\n",
    "    label=r'L$_1$ reg.', color=lasso_dii_color, marker='o', linestyle='-'\n",
    ")\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    random_times/max_time,\n",
    "    label='random', color=random_dii_color, marker='^', linestyle='-.', alpha=0.8\n",
    ")\n",
    "time_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    kernel_lowers/max_time,\n",
    "    kernel_uppers/max_time,\n",
    "    alpha=0.4, color=lasso_dii_color\n",
    ")\n",
    "time_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    random_lowers/max_time,\n",
    "    random_uppers/max_time,\n",
    "    alpha=0.2, color=random_dii_color\n",
    ")\n",
    "time_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "time_ax.set_ylabel(\"Runtime [au]\", fontsize=fontsize)\n",
    "time_ax.tick_params(axis='x', which='both', labelsize=fontsize)\n",
    "time_ax.tick_params(axis='y', which='both', left=True, labelleft=True, labelsize=fontsize)\n",
    "time_ax.grid(axis='y')\n",
    "time_ax.legend(fontsize=fontsize)\n",
    "\n",
    "dii_ax = axes[0]\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(1, greedy_imbs.shape[0]+1), greedy_imbs[::-1, -1],\n",
    "    'D--', label='greedy weighted optimisation', color=greedy_dii_color\n",
    ")\n",
    "dii_ax.fill_between(\n",
    "    range(1, len(batched_greedy_imbalances)+1), \n",
    "    np.min(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    np.max(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    alpha=0.4, color=greedy_dii_color,\n",
    ")\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], kernel_imbs[where_gammas_found],\n",
    "    'o-', label='lasso optimisation', color=lasso_dii_color\n",
    ")\n",
    "dii_ax.fill_between(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], \n",
    "    np.min(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    np.max(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    alpha=0.4, color=lasso_dii_color,\n",
    ")\n",
    "\n",
    "if False:\n",
    "    dii_ax.plot(\n",
    "        np.arange(1, kernel_imbs.shape[0]+1), \n",
    "        np.min(batched_random_imbalances, axis=1),\n",
    "        '^', alpha=0.8, color=random_dii_color,\n",
    "    )\n",
    "    dii_ax.plot(\n",
    "        np.arange(1, kernel_imbs.shape[0]+1), \n",
    "        np.max(batched_random_imbalances, axis=1),\n",
    "        '^', alpha=0.8, color=random_dii_color,\n",
    "    )\n",
    "dii_ax.vlines(\n",
    "    np.arange(1, kernel_imbs.shape[0]+1), \n",
    "    np.min(batched_random_imbalances, axis=1),\n",
    "    np.max(batched_random_imbalances, axis=1),\n",
    "    alpha=0.8, color=random_dii_color, linewidth=3,\n",
    "    # linestyle='--'\n",
    ")\n",
    "\n",
    "# dii_ax.set_xlabel('Number of non-zero features', fontsize=fontsize)\n",
    "dii_ax.set_ylabel(\"DII\", fontsize=fontsize)\n",
    "dii_ax.tick_params(\n",
    "    axis='x', which='both', labelsize=fontsize, \n",
    "    bottom=True, labelbottom=True, top=False, labeltop=False\n",
    ")\n",
    "dii_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "dii_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "dii_ax.set_ylim([0.05, 0.5])\n",
    "dii_ax.set_xlim([1, 30])\n",
    "\n",
    "dii_ax.legend(\n",
    "    handles=[\n",
    "        Line2D([-1], [-1], marker='o', linestyle='-', color=lasso_dii_color, label=r'L$_1$ reg.'),\n",
    "        Line2D([-1], [-1], marker='D', linestyle='--', color=greedy_dii_color, label='greedy'),\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='', elinewidth=3, linestyle='', color=random_dii_color, label='random', alpha=0.8),\n",
    "    ],\n",
    "    ncols=3, columnspacing=0.5, handletextpad=0.3, handlelength=2.5,\n",
    "    fontsize=fontsize\n",
    ")\n",
    "\n",
    "mae_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "mae_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.2f}\"))\n",
    "time_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "time_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "\n",
    "dii_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "dii_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"waterphase_final.pdf\", format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Plotted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figa_data = np.empty((kernel_imbs.shape[0]-1, 9), dtype=np.float32)\n",
    "nfeat_indices = range(1, len(figa_data)+1)\n",
    "\n",
    "figa_data[:, 0] = nfeat_indices\n",
    "figa_data[:, 1] = kernel_imbs[:][1:]\n",
    "figa_data[:, 2] = np.min(batched_lasso_imbalances[:, :], axis=1)[1:]\n",
    "figa_data[:, 3] = np.max(batched_lasso_imbalances[:, :], axis=1)[1:]\n",
    "\n",
    "figa_data[:, 4] = greedy_imbs[::-1, -1]\n",
    "figa_data[:, 5] = np.min(batched_greedy_imbalances[::-1, :], axis=1)\n",
    "figa_data[:, 6] = np.max(batched_greedy_imbalances[::-1, :], axis=1)\n",
    "\n",
    "figa_data[:, 7] = np.min(batched_random_imbalances, axis=1)[1:]\n",
    "figa_data[:, 8] = np.max(batched_random_imbalances, axis=1)[1:]\n",
    "\n",
    "figa_data[np.logical_not(where_gammas_found[1:]), 1:4] = np.nan\n",
    "\n",
    "np.savetxt(\n",
    "    \"fig3a_data.csv\", figa_data, delimiter=',', \n",
    "    fmt=\"%u %.6e %.6e %.6e %.6e %.6e %.6e %.6e %.6e\",\n",
    "    header=\"n_features lasso_dii lasso_min_dii lasso_max_dii greedy_dii greedy_mi_dii greedy_max_dii random_dii random_min_dii random_max_dii\"\n",
    ")\n",
    "\n",
    "figb_data = np.empty((len(kernel_keys), 7), dtype=np.float32)\n",
    "figb_indices = np.array([int(kernel_key) for kernel_key in kernel_keys], dtype=int)\n",
    "\n",
    "figb_data[:, 0] = figb_indices\n",
    "for ii_key, kernel_key in enumerate(kernel_keys):\n",
    "    figb_data[ii_key, 1] = np.mean(results_dict[kernel_key][\"rmses\"])\n",
    "    figb_data[ii_key, 2] = np.min(results_dict[kernel_key][\"rmses\"])\n",
    "    figb_data[ii_key, 3] = np.max(results_dict[kernel_key][\"rmses\"])\n",
    "\n",
    "for ii_key, rand_key in enumerate(rand_keys):\n",
    "    figb_data[ii_key, 4] = np.mean(results_dict[rand_key][\"rmses\"])\n",
    "    figb_data[ii_key, 5] = np.min(results_dict[rand_key][\"rmses\"])\n",
    "    figb_data[ii_key, 6] = np.max(results_dict[rand_key][\"rmses\"])\n",
    "\n",
    "np.savetxt(\n",
    "    \"fig3b_data.csv\", figb_data, delimiter=',', \n",
    "    fmt=\"%u %.6e %.6e %.6e %.6e %.6e %.6e\",\n",
    "    header=\"n_features lasso_mean[eV\\A] lasso_min[eV\\A] lasso_max[eV\\A] random[eV\\A] random_min[eV\\A] random_max[eV\\A]\"\n",
    ")\n",
    "\n",
    "figc_data = np.empty((len(kernel_keys), 7), dtype=np.float32)\n",
    "figc_indices = np.array([int(kernel_key) for kernel_key in kernel_keys], dtype=int)\n",
    "\n",
    "figc_data[:, 0] = figc_indices\n",
    "for ii_key, kernel_key in enumerate(kernel_keys):\n",
    "    figc_data[ii_key, 1] = np.mean(results_dict[kernel_key][\"runtimes\"])\n",
    "    figc_data[ii_key, 2] = np.min(results_dict[kernel_key][\"runtimes\"])\n",
    "    figc_data[ii_key, 3] = np.max(results_dict[kernel_key][\"runtimes\"])\n",
    "\n",
    "for ii_key, rand_key in enumerate(rand_keys):\n",
    "    figc_data[ii_key, 4] = np.mean(results_dict[rand_key][\"runtimes\"])\n",
    "    figc_data[ii_key, 5] = np.min(results_dict[rand_key][\"runtimes\"])\n",
    "    figc_data[ii_key, 6] = np.max(results_dict[rand_key][\"runtimes\"])\n",
    "\n",
    "np.savetxt(\n",
    "    \"fig3c_data.csv\", figc_data, delimiter=',', \n",
    "    fmt=\"%u %.6e %.6e %.6e %.6e %.6e %.6e\",\n",
    "    header=\"n_features lasso_mean[s] lasso_min[s] lasso_max[s] random[s] random_min[s] random_max[s]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dii_ms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
