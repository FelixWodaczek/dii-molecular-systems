{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Gradient Optimisation for Feature Selection on Water Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ase.io import read as ase_read\n",
    "\n",
    "from dadapy.feature_weighting import FeatureWeighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Large SOAP datasets and especially ACSFs are somewhat slow to calculate, so I mostly just run this on our local cluster and then load from numpy files.\n",
    "To recalculate the descriptors, use `make_descriptors.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"../data\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ase.Atoms objects for each liquid configuration\n",
    "liquid_frames = ase_read(data_dir.joinpath(\"ice_in_water_data/dataset_1000_eVAng.xyz\"), index=':')\n",
    "n_atoms = np.sum(np.asarray([len(frame) for frame in liquid_frames], dtype=np.int16))\n",
    "atom_types = np.zeros((n_atoms), dtype=np.int8)\n",
    "\n",
    "# Collect some metadata, like how many atoms/config, atoms in total and which atom is even an oxygen.\n",
    "counter = 0\n",
    "for frame in liquid_frames:\n",
    "    atom_types[counter:counter+len(frame)] = frame.get_atomic_numbers()\n",
    "    counter+=len(frame)\n",
    "is_o = atom_types==8\n",
    "is_h = np.logical_not(is_o)\n",
    "\n",
    "print(f\"Found {np.count_nonzero(is_o)} Oxygen atoms and {np.count_nonzero(is_h)} Hydrogen atoms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new descriptors from file or laod ase.Atoms objects and recalculate\n",
    "# Recalculation here works best when just getting SOAPs, ACSF takes a little long\n",
    "average_soap = np.load(data_dir.joinpath(\"ice_in_water_data/average_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "atomic_soap = np.load(data_dir.joinpath(\"ice_in_water_data/singleatom_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_soap.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_soap.shape)\n",
    "\n",
    "# The file format of the input file the descriptors are calculated from is 54 solid, 1000 liquid\n",
    "# So we can just get the liquid configurations by getting the number of atoms n_atoms in the liquid configurations\n",
    "# From the end of the decriptor matrix\n",
    "liquid_atomic_soap = atomic_soap[-n_atoms:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_acsf = np.asarray(np.load(data_dir.joinpath(\"ice_in_water_data/average_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "atomic_acsf = np.asarray(np.load(data_dir.joinpath(\"ice_in_water_data/singleatom_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "liquid_atomic_acsf = atomic_acsf[-n_atoms:, :].copy()\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_acsf.shape)\n",
    "print(\"Fetched computed liquid atomic SOAP descriptors for %u configurations and with %u features each.\"%liquid_atomic_acsf.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_acsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing of Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf]\n",
    "for desc in descriptors:\n",
    "    desc /= np.linalg.norm(desc, axis=-1)[:, np.newaxis]\n",
    "average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf = descriptors\n",
    "\n",
    "# apparently atomic acsf sometimes become nan, set to 0\n",
    "nan_frames = np.argwhere(np.isnan(atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "atomic_acsf[nan_frames, :] = 0.\n",
    "\n",
    "nan_frames = np.argwhere(np.isnan(liquid_atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in liquid atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "liquid_atomic_acsf[nan_frames, :] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Input and Target Data\n",
    "\n",
    "`target_data` is the space which delivers the target ranks, `input_space` is the space for which the gammas should be optimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "# random_selection = rng.choice(liquid_atomic_soap.shape[0], 300)\n",
    "target_data = liquid_atomic_soap[::500]\n",
    "input_space = liquid_atomic_acsf[::500]\n",
    "\n",
    "fw_input = FeatureWeighting(coordinates=input_space, maxk=input_space.shape[0]-1, verbose=True)\n",
    "fw_target = FeatureWeighting(coordinates=target_data, maxk=target_data.shape[0]-1, verbose=True)\n",
    "\n",
    "if True:\n",
    "    stds = np.std(input_space, axis=0)\n",
    "    stds[stds==0.] = 1.\n",
    "    standardised_input = input_space/stds[np.newaxis, :]\n",
    "    # dist_matrix = kimb.compute_dist_matrix(data=target_data.astype(np.double), period=np.zeros((target_data.shape[-1])))\n",
    "    # truth_ranks = stats.rankdata(dist_matrix, method='average', axis=1).astype(int, copy=False)\n",
    "\n",
    "print(f\"Working on ground truth shaped {target_data.shape} and optimising space of shape {input_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Optimal Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gammas = np.ones((input_space.shape[-1],), dtype=np.double)\n",
    "lr_list = np.logspace(-2, 2, 10)\n",
    "\n",
    "opt_l_rate = fw_input.return_optimal_learning_rate(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None, \n",
    "    n_epochs=50, decaying_lr=True, \n",
    "    n_samples=154, trial_learning_rates=lr_list,\n",
    ")\n",
    "\n",
    "kernel_imbalances_list = fw_input.history['dii_per_epoch_per_lr'][np.argwhere(opt_l_rate==lr_list)[0, 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "ax.plot(kernel_imbalances_list, label=\"kernel imbalances\")\n",
    "\n",
    "ax.set_title(\"Loss for optimal learning rate %f\"%opt_l_rate)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_ylabel('Kernel Imbalance')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise using Lasso Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    num_nonzero_features,\n",
    "    l1_penalties_opt_per_nfeatures,\n",
    "    dii_opt_per_nfeatures, \n",
    "    weights_opt_per_nfeatures\n",
    ") = fw_input.return_lasso_optimization_dii_search(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None, \n",
    "    learning_rate=opt_l_rate, constrain=True, decaying_lr=True,\n",
    "    n_epochs=100, refine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing Gammas from Lasso Optimisation\n",
    "\n",
    "The weights returned by lasso optimisation are returned unordered.\n",
    "This recalculates the information imbalance for each entry and orders the weights by number of non-zero features and best information imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert order so it has least features first\n",
    "kernel_imbs = dii_opt_per_nfeatures[::-1]\n",
    "lasso_gammas = weights_opt_per_nfeatures[::-1]\n",
    "num_nonzero_features = num_nonzero_features[::-1]\n",
    "l1_penalties_opt_per_nfeatures = l1_penalties_opt_per_nfeatures[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Backwards Greedy Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ndim_red times, find the optimal representation\n",
    "ndims = input_space.shape[-1]\n",
    "delete_indices = []\n",
    "classic_greedy_imbalances = np.zeros((ndims-1,), dtype=np.float32)\n",
    "for ndim in range(ndims-1):\n",
    "    print(\"Removing %u features out of %u\"%(ndim, ndims))\n",
    "    information_imbalances = []\n",
    "\n",
    "    # Add kd-trees for current best guess appended with each new candidate\n",
    "    candidates = np.setdiff1d(np.arange(standardised_input.shape[-1]), delete_indices)\n",
    "    for candidate in candidates:\n",
    "        candidate_representation = np.delete(standardised_input, delete_indices+[candidate], axis=-1)\n",
    "        information_imbalances.append(get_lambdaopt_kimb(candidate_representation, truth_ranks))\n",
    "\n",
    "    best_cand_ind = np.argmin(np.asarray(information_imbalances))\n",
    "    delete_indices.append(candidates[best_cand_ind])\n",
    "    classic_greedy_imbalances[ndim] = get_lambdaopt_kimb(\n",
    "        np.delete(standardised_input, delete_indices, axis=-1),\n",
    "        truth_ranks\n",
    "    )\n",
    "classic_delete_indices = np.asarray(delete_indices, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Backwards Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_gammas, greedy_imbs = fw_input.return_backward_greedy_dii_elimination(\n",
    "    target_data=fw_target, initial_weights=initial_gammas, lambd=None,\n",
    "    initial_weights=initial_gammas, lambd=None, n_epochs=80,\n",
    "    l_rate=opt_l_rate, constrain=False, decaying_lr=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations and Plotting\n",
    "\n",
    "If no recalculations are needed just go to this part and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='load_old'\n",
    "if mode=='save_new':\n",
    "    np.save(data_dir.joinpath('water_phase_store/kernel_imbs_hartbohr_lambda.npy'), kernel_imbs)\n",
    "    np.save(data_dir.joinpath('water_phase_store/lasso_gammas_hartbohr_lambda.npy'), lasso_gammas)\n",
    "    np.save(data_dir.joinpath('water_phase_store/classic_greedy_imbalances_hartbohr_lambda.npy'), classic_greedy_imbalances)\n",
    "    np.save(data_dir.joinpath('water_phase_store/classic_delete_indices_hartbohr_lambda.npy'), classic_delete_indices)\n",
    "    np.save(data_dir.joinpath(\"water_phase_store/greedy_gammas_hartbohr_lambda.npy\"), greedy_gammas)\n",
    "    np.save(data_dir.joinpath(\"water_phase_store/greedy_imbs_hartbohr_lambda.npy\"), greedy_imbs)\n",
    "elif mode=='load_old':\n",
    "    kernel_imbs = np.load(data_dir.joinpath('water_phase_store/kernel_imbs_hartbohr_lambda.npy'))\n",
    "    lasso_gammas = np.load(data_dir.joinpath('water_phase_store/lasso_gammas_hartbohr_lambda.npy'))\n",
    "    classic_greedy_imbalances = np.load(data_dir.joinpath('water_phase_store/classic_greedy_imbalances_hartbohr_lambda.npy'))\n",
    "    classic_delete_indices = np.load(data_dir.joinpath('water_phase_store/classic_delete_indices_hartbohr_lambda.npy'))\n",
    "    greedy_gammas = np.load(data_dir.joinpath(\"water_phase_store/greedy_gammas_hartbohr_lambda.npy\"))\n",
    "    greedy_imbs = np.load(data_dir.joinpath(\"water_phase_store/greedy_imbs_hartbohr_lambda.npy\"))\n",
    "\n",
    "where_gammas_found = (kernel_imbs!=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "rng = np.random.default_rng()\n",
    "batch_indices = rng.choice(liquid_atomic_soap.shape[0], size=(n_batches, input_space.shape[0]), replace=False)\n",
    "\n",
    "true_fws = []\n",
    "for batch in batch_indices:\n",
    "    true_fws.append(FeatureWeighting(\n",
    "        coordinates=liquid_atomic_soap[batch, :], maxk=len(batch)-1, verbose=False\n",
    "    ))\n",
    "\n",
    "print(\"Kernel Imbalance\")\n",
    "batched_lasso_imbalances = np.empty((len(kernel_imbs), n_batches), dtype=np.float32)\n",
    "for n_dims in range(len(kernel_imbs)):\n",
    "    if where_gammas_found[n_dims]:\n",
    "        for ii_batch, batch in enumerate(batch_indices):\n",
    "            batched_lasso_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "                coordinates=liquid_atomic_acsf[batch, :]*lasso_gammas[n_dims, :], maxk=len(batch)-1, verbose=False\n",
    "            ).return_dii(\n",
    "                target_data=true_fws[ii_batch],\n",
    "                lambd=None\n",
    "            )\n",
    "\n",
    "print(\"Classic Greedy Imbalance\")\n",
    "batched_classic_imbalances = np.empty((len(classic_greedy_imbalances), n_batches), dtype=np.float32)\n",
    "for n_dims in range(len(classic_delete_indices)):\n",
    "    for ii_batch, batch in enumerate(batch_indices):\n",
    "        batched_classic_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "            coordinates=np.delete(liquid_atomic_acsf[batch, :]/stds[np.newaxis, :], classic_delete_indices[:n_dims+1], axis=-1),\n",
    "            maxk=len(batch)-1, verbose=False,\n",
    "        ).return_dii(\n",
    "            target_data=true_fws[ii_batch],\n",
    "            lambd=None\n",
    "        )\n",
    "\n",
    "print(\"Greedy Imbalance\")\n",
    "batched_greedy_imbalances = np.empty((len(greedy_imbs), n_batches), dtype=np.float32)\n",
    "for n_dims in range(greedy_gammas.shape[-1]):\n",
    "    for ii_batch, batch in enumerate(batch_indices):\n",
    "        batched_greedy_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "            coordinates=liquid_atomic_acsf[batch, :]*greedy_gammas[n_dims, -1, :], \n",
    "            maxk=len(batch)-1, verbose=False,\n",
    "        ).return_dii(\n",
    "            target_data=true_fws[ii_batch],\n",
    "            lambd=None\n",
    "        )\n",
    "\n",
    "print(\"Greedy only Select\")\n",
    "greedy_select_imbalance = np.empty((greedy_gammas.shape[-1], ), dtype=np.float32)\n",
    "for n_dims in range(greedy_gammas.shape[-1]):\n",
    "    greedy_select_imbalance[n_dims] = FeatureWeighting(\n",
    "        coordinates=(input_space/stds[np.newaxis, :])[:, greedy_gammas[n_dims, -1, :]!=0],\n",
    "        maxk=len(batch)-1, verbose=False,\n",
    "    ).return_dii(\n",
    "        target_data=fw_target,\n",
    "        lambd=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Greedy only Select\")\n",
    "greedy_select_imbalance = np.empty((greedy_gammas.shape[-1], ), dtype=np.float32)\n",
    "for n_dims in range(greedy_gammas.shape[-1]):\n",
    "    greedy_select_imbalance[n_dims] = FeatureWeighting(\n",
    "        coordinates=(input_space/stds[np.newaxis, :])[:, greedy_gammas[n_dims, -1, :]!=0], \n",
    "        maxk=len(batch)-1, verbose=False,\n",
    "    ).return_dii(\n",
    "        target_data=fw_target,\n",
    "        lambd=None\n",
    "    )\n",
    "\n",
    "print(\"Random Selection\")\n",
    "batched_random_imbalances = np.empty((len(kernel_imbs), n_batches), dtype=np.float32)\n",
    "rand_gamma_mask = np.zeros((input_space.shape[-1], ), dtype=bool)\n",
    "for n_dims in range(1, len(kernel_imbs)):\n",
    "    for ii_batch, batch in enumerate(batch_indices):\n",
    "        rand_gamma_mask[:] = False\n",
    "        rand_gamma_mask[rng.choice(input_space.shape[-1], size=(n_dims, ), replace=False)] = True\n",
    "        batched_random_imbalances[n_dims, ii_batch] = FeatureWeighting(\n",
    "            coordinates=(liquid_atomic_acsf[batch, :]/stds)[:, rand_gamma_mask], \n",
    "            maxk=len(batch)-1, verbose=False,\n",
    "        ).return_dii(\n",
    "            target_data=true_fws[ii_batch],\n",
    "            lambd=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "where_gammas_found = (kernel_imbs!=0.)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "\n",
    "if False:\n",
    "    ax.plot(range(1, len(classic_greedy_imbalances)+1), classic_greedy_imbalances[::-1], 'x--', label='classic greedy')\n",
    "    ax.fill_between(\n",
    "        range(1, len(classic_greedy_imbalances)+1), \n",
    "        np.min(batched_classic_imbalances[::-1, :], axis=1),\n",
    "        np.max(batched_classic_imbalances[::-1, :], axis=1),\n",
    "        alpha=0.3, linewidth=10\n",
    "    )\n",
    "    ax.plot(\n",
    "    np.arange(1, greedy_select_imbalance.shape[0]+1), greedy_select_imbalance[::-1],\n",
    "    'o--', label='greedy select'\n",
    "    )\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], kernel_imbs[where_gammas_found],\n",
    "    'o--', label='lasso optimisation'\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], \n",
    "    np.min(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    np.max(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(1, greedy_imbs.shape[0]+1), greedy_imbs[::-1, -1],\n",
    "    'o--', label='greedy weighted optimisation'\n",
    ")\n",
    "ax.fill_between(\n",
    "    range(1, len(batched_greedy_imbalances)+1), \n",
    "    np.min(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    np.max(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    alpha=0.3, linewidth=10\n",
    ")\n",
    "\n",
    "ax.vlines(\n",
    "    np.arange(1, kernel_imbs.shape[0]+1), \n",
    "    np.min(batched_random_imbalances, axis=1),\n",
    "    np.max(batched_random_imbalances, axis=1),\n",
    "    alpha=0.8, color='tab:grey', linewidth=5, label='random selection'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Dimensions')\n",
    "ax.set_ylabel(r'$DII(S^{red} \\to S^{true})$')\n",
    "ax.set_title(\"Comparison of %u ACSF descriptors to %u SOAP descriptors\\nfor %u different atom environments\"%(input_space.shape[1], target_data.shape[-1], input_space.shape[0]))\n",
    "ax.legend()\n",
    "ax.set_ylim([0., 0.6])\n",
    "ax.set_xlim([1, 30])\n",
    "\n",
    "fig.savefig(\"ii_history_acsf%u_c%u.png\"%input_space.shape[::-1], format='png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "target_dir = data_dir.joinpath(\"n2p2_fitting/240930_pots_errorbars_out_predict/\")\n",
    "\n",
    "results_dict = {}\n",
    "for logfile in target_dir.glob('*.log'):\n",
    "    with open(logfile, 'r') as f:\n",
    "        content = f.read()\n",
    "        runtype = re.search(\"231213_pot_acsf(.*)_hartbohr_scaleunits_bcdata_lambda\", content).group(1)\n",
    "        run_num = re.search(\"run_([0-9]*)\", content).group(1)\n",
    "\n",
    "        # memory_kb = re.search(\"\\s([0-9]*)maxresident\", content).group(1)\n",
    "        runtime_s = re.search(\"user\\s0m([0-9]*\\.[0-9]*)\", content).group(1)\n",
    "        \n",
    "        pot_dir = target_dir.joinpath(\"231213_pot_acsf\"+runtype+\"_hartbohr_scaleunits_bcdata_lambda/run_\"+run_num)\n",
    "\n",
    "        all_errors = np.loadtxt(pot_dir.joinpath('learning-curve.out'))\n",
    "        all_errors[:, 1:9] *= 27.211386245988\n",
    "        all_errors[:, 9:13] *= 51.421 # Hartree/Bohr to eV/Angstrom conversion\n",
    "        rmse_ftest_evA = all_errors[-1, 12]\n",
    "        \n",
    "        if runtype not in results_dict:\n",
    "            results_dict[runtype] = {\"runtimes\": [], \"rmses\": []}\n",
    "        \n",
    "        results_dict[runtype][\"runtimes\"].append(float(runtime_s))\n",
    "        results_dict[runtype][\"rmses\"].append(rmse_ftest_evA) \n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "fontsize = 12\n",
    "\n",
    "if False:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"Helvetica\",\n",
    "        \"font.size\": fontsize,\n",
    "        'text.latex.preamble': r'\\usepackage{amsmath}'\n",
    "    })\n",
    "\n",
    "double_ax = False\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 6))\n",
    "\n",
    "kernel_keys = ['10', '18', '25', '38', '50', '176']\n",
    "rand_keys = ['10rand', '18rand', '25rand', '38rand', '50rand', '176']\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "\n",
    "rcolor = \"#3f4e32\" # cmap(0.1)\n",
    "lcolor = \"#6a272a\" # cmap(0.9)\n",
    "greedy_dii_color = \"#f29944\" # cmap(0.6)\n",
    "lasso_dii_color = \"#989ec1\" # cmap(0.3)\n",
    "random_dii_color = \"tab:grey\"\n",
    "\n",
    "mae_ax = axes[1]\n",
    "\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    label=r'L$_1$ reg.', color=lcolor, marker='o', linestyle='-'\n",
    ")\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    label='random', color=lcolor, marker='^', linestyle='-.'\n",
    ")\n",
    "# mae_ax.plot(176, results_dict['176'][\"rmse\"], color='tab:green', marker='o', markersize=4)\n",
    "mae_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "\n",
    "mae_ax.set_ylabel(\"Test Force RMSE [eV/A]\", color=lcolor, fontsize=fontsize)\n",
    "mae_ax.grid(axis='y', color=lcolor)\n",
    "mae_ax.tick_params(axis='x', which='both', top=True, labeltop=False, labelsize=fontsize)\n",
    "if double_ax:\n",
    "    mae_ax.tick_params(axis='y', which='both', color=lcolor, labelcolor=lcolor, labelsize=fontsize)\n",
    "else:\n",
    "    mae_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "# mae_ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(4))\n",
    "# axes[0].set_xscale('log')\n",
    "# axes[0].set_yscale('log')\n",
    "\n",
    "time_ax = mae_ax.twinx()\n",
    "\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    [np.mean(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys],\n",
    "    label=r'L$_1$ reg.', color=rcolor, marker='o', linestyle='-'\n",
    ")\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    [np.mean(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys],\n",
    "    label='random', color=rcolor, marker='^', linestyle='-.'\n",
    ")\n",
    "# time_ax.plot(176, results_dict['176'][\"runtime\"], color='tab:green', marker='o', markersize=4)\n",
    "time_ax.set_ylabel(\"Runtime [au]\", color=rcolor, fontsize=fontsize)\n",
    "time_ax.yaxis.set_label_position(\"right\")\n",
    "time_ax.tick_params(axis='x', which='both', bottom=False, labelbottom=False, labelsize=fontsize)\n",
    "time_ax.tick_params(axis='y', which='both', left=False, labelleft=False, right=True, labelright=True, color=rcolor, labelcolor=rcolor, labelsize=fontsize)\n",
    "# time_ax.grid(axis='y', color=rcolor)\n",
    "# time_ax.yaxis.set_major_locator(mpl.ticker.LinearLocator(4))\n",
    "\n",
    "# time_ax.set_ylim((0, 75))\n",
    "# mae_ax.set_ylim((0, 0.3))\n",
    "\n",
    "dii_ax = axes[0]\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(1, greedy_imbs.shape[0]+1), greedy_imbs[::-1, -1],\n",
    "    'D--', label='greedy weighted optimisation', color=greedy_dii_color\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    range(1, len(batched_greedy_imbalances)+1), \n",
    "    np.min(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    np.max(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    alpha=1, color=greedy_dii_color, linewidth=3\n",
    ")\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], kernel_imbs[where_gammas_found],\n",
    "    'o-', label='lasso optimisation', color=lasso_dii_color\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], \n",
    "    np.min(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    np.max(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    alpha=1, color=lasso_dii_color, linewidth=3\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    np.arange(1, kernel_imbs.shape[0]+1), \n",
    "    np.min(batched_random_imbalances, axis=1),\n",
    "    np.max(batched_random_imbalances, axis=1),\n",
    "    alpha=0.8, color=random_dii_color, linewidth=3\n",
    ")\n",
    "\n",
    "# dii_ax.set_xlabel('Number of non-zero features', fontsize=fontsize)\n",
    "dii_ax.set_ylabel(\"DII\", fontsize=fontsize)\n",
    "dii_ax.tick_params(\n",
    "    axis='x', which='both', labelsize=fontsize, \n",
    "    bottom=True, labelbottom=True, top=False, labeltop=False\n",
    ")\n",
    "dii_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "# dii_ax.legend(fontsize=fontsize)\n",
    "dii_ax.set_ylim([0.05, 0.5])\n",
    "dii_ax.set_xlim([1, 30])\n",
    "\n",
    "time_ax.legend(\n",
    "    handles=[\n",
    "        Line2D([0], [0], marker='o', linestyle='-', color='k', label=r'L$_1$ reg.', alpha=1),\n",
    "        Line2D([0], [0], marker='^', linestyle='-.', color='k', label='random', alpha=1),\n",
    "    ],\n",
    "    ncols=3, loc=(0.15, 0.85), columnspacing=0.5, handletextpad=0.3, handlelength=2.5,\n",
    "    fontsize=fontsize, \n",
    ")\n",
    "\n",
    "dii_ax.legend(\n",
    "    handles=[\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='o', elinewidth=3, linestyle='-', color=lasso_dii_color, label=r'L$_1$ reg.'),\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='D', elinewidth=3, linestyle='--', color=greedy_dii_color, label='greedy'),\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='', elinewidth=3, linestyle='', color=random_dii_color, label='random', alpha=0.8),\n",
    "    ],\n",
    "    ncols=3, columnspacing=0.5, handletextpad=0.3, handlelength=2.5,\n",
    "    fontsize=fontsize\n",
    ")\n",
    "\n",
    "mae_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "mae_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.2f}\"))\n",
    "time_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "\n",
    "dii_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "dii_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"waterphase_final.png\", format='png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "fontsize = 12\n",
    "\n",
    "if False:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"Helvetica\",\n",
    "        \"font.size\": fontsize,\n",
    "        'text.latex.preamble': r'\\usepackage{amsmath}'\n",
    "    })\n",
    "\n",
    "double_ax = False\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(5, 6))\n",
    "\n",
    "kernel_keys = ['10', '18', '25', '38', '50', '176']\n",
    "rand_keys = ['10rand', '18rand', '25rand', '38rand', '50rand', '176']\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "greedy_dii_color = \"#f29944\" # cmap(0.6)\n",
    "lasso_dii_color = \"#989ec1\" # cmap(0.3)\n",
    "random_dii_color = \"tab:grey\"\n",
    "\n",
    "mae_ax = axes[1]\n",
    "\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    label=r'L$_1$ reg.', color=lasso_dii_color, marker='o', linestyle='-'\n",
    ")\n",
    "mae_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.min(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    [np.max(results_dict[kernel_key][\"rmses\"]) for kernel_key in kernel_keys],\n",
    "    alpha=0.4, color=lasso_dii_color\n",
    ")\n",
    "mae_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.mean(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    label='random', color=random_dii_color, marker='^', linestyle='-.', alpha=0.8\n",
    ")\n",
    "mae_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    [np.min(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    [np.max(results_dict[rand_keys][\"rmses\"]) for rand_keys in rand_keys],\n",
    "    alpha=0.2, color=random_dii_color\n",
    ")\n",
    "mae_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "mae_ax.set_ylabel(\"Test Force RMSE [eV/A]\", fontsize=fontsize)\n",
    "mae_ax.tick_params(axis='x', which='both', labelsize=fontsize)\n",
    "mae_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "mae_ax.grid(axis='y')\n",
    "mae_ax.legend(fontsize=fontsize)\n",
    "\n",
    "time_ax = axes[2]\n",
    "\n",
    "kernel_times = np.array([np.mean(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "kernel_uppers = np.array([np.max(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "kernel_lowers = np.array([np.min(results_dict[kernel_key][\"runtimes\"]) for kernel_key in kernel_keys])\n",
    "random_times = np.array([np.mean(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "random_uppers = np.array([np.max(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "random_lowers = np.array([np.min(results_dict[rand_keys][\"runtimes\"]) for rand_keys in rand_keys])\n",
    "\n",
    "max_time = np.max(np.concatenate([kernel_times, random_times]))\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    kernel_times/max_time,\n",
    "    label=r'L$_1$ reg.', color=lasso_dii_color, marker='o', linestyle='-'\n",
    ")\n",
    "time_ax.plot(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys], \n",
    "    random_times/max_time,\n",
    "    label='random', color=random_dii_color, marker='^', linestyle='-.', alpha=0.8\n",
    ")\n",
    "time_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    kernel_lowers/max_time,\n",
    "    kernel_uppers/max_time,\n",
    "    alpha=0.4, color=lasso_dii_color\n",
    ")\n",
    "time_ax.fill_between(\n",
    "    [int(kernel_key) for kernel_key in kernel_keys],\n",
    "    random_lowers/max_time,\n",
    "    random_uppers/max_time,\n",
    "    alpha=0.2, color=random_dii_color\n",
    ")\n",
    "time_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "time_ax.set_ylabel(\"Runtime [au]\", fontsize=fontsize)\n",
    "time_ax.tick_params(axis='x', which='both', labelsize=fontsize)\n",
    "time_ax.tick_params(axis='y', which='both', left=True, labelleft=True, labelsize=fontsize)\n",
    "time_ax.grid(axis='y')\n",
    "time_ax.legend(fontsize=fontsize)\n",
    "\n",
    "dii_ax = axes[0]\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(1, greedy_imbs.shape[0]+1), greedy_imbs[::-1, -1],\n",
    "    'D--', label='greedy weighted optimisation', color=greedy_dii_color\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    range(1, len(batched_greedy_imbalances)+1), \n",
    "    np.min(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    np.max(batched_greedy_imbalances[::-1, :], axis=1),\n",
    "    alpha=1, color=greedy_dii_color, linewidth=3\n",
    ")\n",
    "\n",
    "dii_ax.plot(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], kernel_imbs[where_gammas_found],\n",
    "    'o-', label='lasso optimisation', color=lasso_dii_color\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    np.arange(kernel_imbs.shape[0])[where_gammas_found], \n",
    "    np.min(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    np.max(batched_lasso_imbalances[where_gammas_found, :], axis=1),\n",
    "    alpha=1, color=lasso_dii_color, linewidth=3\n",
    ")\n",
    "dii_ax.vlines(\n",
    "    np.arange(1, kernel_imbs.shape[0]+1), \n",
    "    np.min(batched_random_imbalances, axis=1),\n",
    "    np.max(batched_random_imbalances, axis=1),\n",
    "    alpha=0.8, color=random_dii_color, linewidth=3\n",
    ")\n",
    "\n",
    "# dii_ax.set_xlabel('Number of non-zero features', fontsize=fontsize)\n",
    "dii_ax.set_ylabel(\"DII\", fontsize=fontsize)\n",
    "dii_ax.tick_params(\n",
    "    axis='x', which='both', labelsize=fontsize, \n",
    "    bottom=True, labelbottom=True, top=False, labeltop=False\n",
    ")\n",
    "dii_ax.tick_params(axis='y', which='both', labelsize=fontsize)\n",
    "dii_ax.set_xlabel(\"Number of non-zero features\", fontsize=fontsize)\n",
    "dii_ax.set_ylim([0.05, 0.5])\n",
    "dii_ax.set_xlim([1, 30])\n",
    "\n",
    "dii_ax.legend(\n",
    "    handles=[\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='o', elinewidth=3, linestyle='-', color=lasso_dii_color, label=r'L$_1$ reg.'),\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='D', elinewidth=3, linestyle='--', color=greedy_dii_color, label='greedy'),\n",
    "        dii_ax.errorbar([-1], [-1], yerr=0, marker='', elinewidth=3, linestyle='', color=random_dii_color, label='random', alpha=0.8),\n",
    "    ],\n",
    "    ncols=3, columnspacing=0.5, handletextpad=0.3, handlelength=2.5,\n",
    "    fontsize=fontsize\n",
    ")\n",
    "\n",
    "mae_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "mae_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.2f}\"))\n",
    "time_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "time_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "\n",
    "dii_ax.xaxis.set_major_formatter(StrMethodFormatter(\"{x:.0f}\"))\n",
    "dii_ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"waterphase_final_stacked.png\", format='png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading out which ACSF are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All this does is give labels for ACSF descriptors, since acsf seems to be missing this functionality\n",
    "acsf_g2 = np.loadtxt(data_dir.joinpath('ice_in_water_data/g2_params_gridsearch_bohr_lambda.txt'))\n",
    "acsf_g4 = np.loadtxt(data_dir.joinpath('ice_in_water_data/g4_params_gridsearch_bohr_lambda.txt'))\n",
    "acsf_species = [1, 8]\n",
    "acsf_symbols = ['H', 'O']\n",
    "acsf_labels = []\n",
    "\n",
    "mask = [True]*len(lasso_gammas[0])\n",
    "counter = 0\n",
    "for symbol in acsf_symbols:\n",
    "    counter+=1\n",
    "    acsf_labels.append(f\"G1 to {symbol}\")\n",
    "    for g2_param in acsf_g2:\n",
    "        counter+=1\n",
    "        acsf_labels.append(f\"G2 to {symbol}, R0={g2_param[1]:.3E}, eta={g2_param[0]*((1./1.8897259886)**2.):.3E}\")\n",
    "for ii_spec1, species1 in enumerate(acsf_species):\n",
    "    for ii_spec2, species2 in enumerate(acsf_species):\n",
    "        if species2 >= species1:\n",
    "            for g4_param in acsf_g4:\n",
    "                if g4_param[2] == 0.:\n",
    "                    mask[counter] = False\n",
    "                counter+=1\n",
    "                acsf_labels.append(f\"G4 with species {acsf_symbols[ii_spec1]} and {acsf_symbols[ii_spec2]}, eta={g4_param[0]*((1./1.8897259886)**2.):.3E}, zeta={g4_param[1]:.3E}, lambda={g4_param[2]:.3E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_imbalance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
