{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Descriptor Selection using Dadapy\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ase.io import read as ase_read\n",
    "\n",
    "from dadapy.feature_weighting import FeatureWeighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('../data').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ase.Atoms objects for each liquid configuration\n",
    "liquid_frames = ase_read(data_dir.joinpath(\"ice_in_water_data/dataset_1000_eVAng.xyz\"), index=':')\n",
    "n_atoms = np.sum(np.asarray([len(frame) for frame in liquid_frames], dtype=np.int16))\n",
    "atom_types = np.zeros((n_atoms), dtype=np.int8)\n",
    "\n",
    "# Collect some metadata, like how many atoms/config, atoms in total and which atom is even an oxygen.\n",
    "counter = 0\n",
    "for frame in liquid_frames:\n",
    "    atom_types[counter:counter+len(frame)] = frame.get_atomic_numbers()\n",
    "    counter+=len(frame)\n",
    "is_o = atom_types==8\n",
    "is_h = np.logical_not(is_o)\n",
    "\n",
    "print(f\"Found {np.count_nonzero(is_o)} Oxygen atoms and {np.count_nonzero(is_h)} Hydrogen atoms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new descriptors from file or laod ase.Atoms objects and recalculate\n",
    "# Recalculation here works best when just getting SOAPs, ACSF takes a little long\n",
    "average_soap = np.load(data_dir.joinpath(\"ice_in_water_data/average_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "atomic_soap = np.load(data_dir.joinpath(\"ice_in_water_data/singleatom_soap_rcut6_nmax6_lmax6_sigma03.npy\"))\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_soap.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_soap.shape)\n",
    "\n",
    "# The file format of the input file the descriptors are calculated from is 54 solid, 1000 liquid\n",
    "# So we can just get the liquid configurations by getting the number of atoms n_atoms in the liquid configurations\n",
    "# From the end of the decriptor matrix\n",
    "liquid_atomic_soap = atomic_soap[-n_atoms:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_acsf = np.asarray(np.load(data_dir.joinpath(\"ice_in_water_data/average_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "atomic_acsf = np.asarray(np.load(data_dir.joinpath(\"ice_in_water_data/singleatom_acsf_rcut6_gridsearch_bohr_lambda.npy\")), dtype=np.float32)\n",
    "liquid_atomic_acsf = atomic_acsf[-n_atoms:, :].copy()\n",
    "print(\"Fetched computed atomic SOAP descriptors for %u configurations and with %u features each.\"%atomic_acsf.shape)\n",
    "print(\"Fetched computed liquid atomic SOAP descriptors for %u configurations and with %u features each.\"%liquid_atomic_acsf.shape)\n",
    "print(\"Fetched computed global SOAP descriptors for %u configurations and with %u features each.\"%average_acsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf]\n",
    "for desc in descriptors:\n",
    "    desc /= np.linalg.norm(desc, axis=-1)[:, np.newaxis]\n",
    "average_soap, atomic_soap, liquid_atomic_soap, average_acsf, atomic_acsf, liquid_atomic_acsf = descriptors\n",
    "\n",
    "# apparently atomic acsf sometimes become nan, set to 0\n",
    "nan_frames = np.argwhere(np.isnan(atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "atomic_acsf[nan_frames, :] = 0.\n",
    "\n",
    "nan_frames = np.argwhere(np.isnan(liquid_atomic_acsf))[:, 0]\n",
    "print(\"Removing %u nan frames in liquid atomic acsf\"%(len(np.unique(nan_frames))))\n",
    "liquid_atomic_acsf[nan_frames, :] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Target Spaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "# random_selection = rng.choice(liquid_atomic_soap.shape[0], 300)\n",
    "target_data = liquid_atomic_soap[::500]\n",
    "input_space = liquid_atomic_acsf[::500]\n",
    "\n",
    "stds = np.std(input_space, axis=0)\n",
    "stds[stds==0.] = 1.\n",
    "standardised_input = input_space/stds[np.newaxis, :]\n",
    "\n",
    "print(f\"Working on ground truth shaped {target_data.shape} and optimising space of shape {input_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "### Regular ACSF to SOAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100  # number of training epochs\n",
    "l1s=np.logspace(np.log10(0.05), np.log10(0.2), 30) # [0 ,0.1, 10, 1000, 100000]\n",
    "\n",
    "f = FeatureWeighting(coordinates=input_space, verbose=True, maxk=input_space.shape[0]-1)\n",
    "f_target = FeatureWeighting(coordinates=target_data, maxk=input_space.shape[0]-1)\n",
    "\n",
    "(\n",
    "    num_nonzero_features,\n",
    "    l1_penalties_opt_per_nfeatures,\n",
    "    dii_opt_per_nfeatures,\n",
    "    weights_opt_per_nfeatures,\n",
    ") = f.return_lasso_optimization_dii_search(\n",
    "    target_data=f_target,\n",
    "    initial_weights=np.ones((input_space.shape[-1])),  # (default) set automatically\n",
    "    n_epochs=n_epochs,\n",
    "    l1_penalties=l1s,\n",
    "    learning_rate=True,  # (default) set automatically\n",
    "    refine=False,\n",
    "    plotlasso=True,  # automatically show DII vs number of non-zero features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.history.keys())\n",
    "print(f.history[\"weights_per_l1_per_epoch\"].shape)\n",
    "print(np.count_nonzero(f.history[\"weights_per_l1_per_epoch\"][:, -1, :], axis=-1))\n",
    "print(f.history[\"l1_penalties\"])\n",
    "\n",
    "print(num_nonzero_features)\n",
    "print(l1_penalties_opt_per_nfeatures)\n",
    "print(dii_opt_per_nfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 0 stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds_input = np.std(input_space, axis=0)\n",
    "print(\"Removing dimensions with zero variance: \")\n",
    "print(np.argwhere(stds_input==0.))\n",
    "shortened_input = input_space[:, stds_input>0.].copy()\n",
    "print(input_space.shape)\n",
    "print(shortened_input.shape)\n",
    "shortened_f = FeatureWeighting(coordinates=shortened_input, verbose=True, maxk=shortened_input.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    shortened_num_nonzero_features,\n",
    "    shortened_l1_penalties_opt_per_nfeatures,\n",
    "    shortened_dii_opt_per_nfeatures,\n",
    "    shortened_weights_opt_per_nfeatures,\n",
    ") = shortened_f.return_lasso_optimization_dii_search(\n",
    "    target_data=f_target,\n",
    "    initial_weights=np.ones((shortened_input.shape[-1])),  # (default) set automatically\n",
    "    n_epochs=n_epochs,\n",
    "    l1_penalties=l1s,\n",
    "    learning_rate=True,  # (default) set automatically\n",
    "    refine=False,\n",
    "    plotlasso=True,  # automatically show DII vs number of non-zero features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise with 1/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdnormed_l1s=np.logspace(-3, 3, 10)\n",
    "\n",
    "(\n",
    "    stdnormed_num_nonzero_features,\n",
    "    stdnormed_l1_penalties_opt_per_nfeatures,\n",
    "    stdnormed_dii_opt_per_nfeatures,\n",
    "    stdnormed_weights_opt_per_nfeatures,\n",
    ") = shortened_f.return_lasso_optimization_dii_search(\n",
    "    target_data=f_target,\n",
    "    initial_weights=None,  # (default) set automatically\n",
    "    n_epochs=n_epochs,\n",
    "    l1_penalties=stdnormed_l1s,\n",
    "    learning_rate=True,  # (default) set automatically\n",
    "    refine=True,\n",
    "    plotlasso=True,  # automatically show DII vs number of non-zero features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_imbs = np.load(data_dir.joinpath('water_phase_store/kernel_imbs_hartbohr_lambda.npy'))\n",
    "lasso_gammas = np.load(data_dir.joinpath('water_phase_store/lasso_gammas_hartbohr_lambda.npy'))\n",
    "\n",
    "n_true = 5\n",
    "true_indices = np.argwhere(lasso_gammas[n_true, :]!=0.)\n",
    "print(f\"Indices with {n_true} true values:\")\n",
    "print(true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdnormed_weights_opt_per_nfeatures.shape\n",
    "\n",
    "feature_inds = [np.argwhere(np.logical_and(weights!=0, np.logical_not(np.isnan(weights)))) for weights in stdnormed_weights_opt_per_nfeatures]\n",
    "for ii, feature_ind in enumerate(feature_inds):\n",
    "    print(len(feature_inds) - ii, np.intersect1d(feature_ind, true_indices), len(feature_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dadapy_usage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
