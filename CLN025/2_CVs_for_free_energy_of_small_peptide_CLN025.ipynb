{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from dadapy.feature_weighting import FeatureWeighting\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import font_manager\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.weight'] = 'light'\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"axes.labelweight\"] = \"light\"\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d8c35",
   "metadata": {},
   "source": [
    "# Note\n",
    "- Weights are referred to as \"gammas\" in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2027573",
   "metadata": {},
   "source": [
    "# Load the collective variables\n",
    "- all 4278 heavy atom pairwise distances as groundtruth\n",
    "- ten other collective variables as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84688095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all heavy atom distances\n",
    "dist = np.load('./cln025_groundtruth_CVs.npy')\n",
    "dist=dist[:,1:]\n",
    "dist=dist[-40000:] # cut away the equilibration time\n",
    "\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_classic = np.loadtxt('./cln025_input_CVs.txt')\n",
    "inputs_classic = inputs_classic[-40000:,[1,2,3,5,6,7,4,8,9,10]] # cut away equilibration and reorder columns\n",
    "\n",
    "header_classic=['timestep', 'rgyr', 'antibetasheet', 'alphahelical', 'numhydroph', 'numhb_bb', 'numhb_sc', 'numhb_mixed', 'pc1', 'pc2', 'pc_res']\n",
    "header_classic = np.array(header_classic)[[1,2,3,5,6,7,4,8,9,10]]\n",
    "\n",
    "inputs_classic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbef9b",
   "metadata": {},
   "source": [
    "### Make index combination for full combinatoric search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d024bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "ind=[]\n",
    "for i in range(10):\n",
    "    ind.append(i)\n",
    "ind = np.array(ind)\n",
    "indices.append(ind[:,np.newaxis])\n",
    "for i in range(2,inputs_classic.shape[1]+1):\n",
    "    ind=np.array(list(itertools.combinations(range(0,inputs_classic.shape[1]),i)))\n",
    "    indices.append(ind)\n",
    "    print(\"the number of combinations of \",i, \" CVs is\", len(ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2271655",
   "metadata": {},
   "source": [
    "# Optimize DII for 1429 points from the full trajetory\n",
    "- Full combinatoric search possible\n",
    "- The subsampling prevents autocorrelations\n",
    "- The below calculation takes 2 hours on an average workstation. Uncomment, if you wish to calculate. Otherwise run the cells in order as they are, to use our precalculated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70aa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# ins_classic = inputs_classic[::28]\n",
    "# dis = dist[::28]\n",
    "\n",
    "# imbalances_opt=[]\n",
    "# gammas_opt = []\n",
    "# #for j in range(len(indices)):\n",
    "# for j in range(0, len(indices)):\n",
    "#     imb=[]\n",
    "#     gams=[]\n",
    "#     print(\"for \", j+1, \" CVs there are \", len(indices[j]), \" combinations\")\n",
    "#     for i in indices[j]:\n",
    "#         print(\"optimizing combi \", i, \" for \", j, \" CVs\" )  \n",
    "#         target_object = FeatureWeighting(dis)\n",
    "#         inputs_object = FeatureWeighting(ins_classic[:,i])\n",
    "#         w = inputs_object.return_weights_optimize_dii(\n",
    "#             target_data = target_object,\n",
    "#             n_epochs = 80,\n",
    "#             constrain = False,\n",
    "#             initial_weights = None,\n",
    "#             lambd = None,\n",
    "#             learning_rate = None,\n",
    "#             l1_penalty = 0.0,\n",
    "#             decaying_lr = \"exp\"\n",
    "#         )\n",
    "#         dii = inputs_object.history[\"dii_per_epoch\"]\n",
    "#         weights = inputs_object.history[\"weights_per_epoch\"]\n",
    "#         imb.append(dii)\n",
    "#         gams.append(weights)\n",
    "#     imbalances_opt.append(imb)\n",
    "#     gammas_opt.append(gams)\n",
    "# end=time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# # np.save('./ANALYSIS/FULL_COMBINATORICS/imbalances_opt_cut_eq.npy', np.array(imbalances_opt, dtype=object))\n",
    "# # np.save('./ANALYSIS/FULL_COMBINATORICS/gammas_opt_cut_eq.npy', np.array(gammas_opt, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d298ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalances_opt = np.load('./ANALYSIS/FULL_COMBINATORICS/imbalances_opt_cut_eq.npy',allow_pickle=True)\n",
    "gammas_opt = np.load('./ANALYSIS/FULL_COMBINATORICS/gammas_opt_cut_eq.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe039ac",
   "metadata": {},
   "source": [
    "#### Select best training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb41b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out for each optimization run the lowest imbalance during the epochs, and the according weights (gammas)\n",
    "\n",
    "imbalances_opt_end = []\n",
    "gammas_opt_end = []\n",
    "for i, imbi in enumerate(imbalances_opt):\n",
    "    imb = []\n",
    "    gamm = []\n",
    "    for jj, j in enumerate(imbi):\n",
    "        #imb.append(j[-1])\n",
    "        imb.append(np.nanmin(j))\n",
    "        gamm.append(gammas_opt[i][jj][np.nanargmin(j)])\n",
    "    imbalances_opt_end.append(imb)\n",
    "    gammas_opt_end.append(gamm)\n",
    "    \n",
    "# now pick out from all the singlets, duplets, etc the lowest one, and according gamma\n",
    "\n",
    "lowimb = []\n",
    "lowimb_index = []\n",
    "lowimb_gamma = []\n",
    "lowimb_tuple = []\n",
    "for i, imb in enumerate(imbalances_opt_end):\n",
    "    lowimb.append(np.min(imb))\n",
    "    lowimb_index.append(np.argmin(imb))\n",
    "    lowimb_gamma.append(gammas_opt_end[i][np.argmin(imb)])\n",
    "    lowimb_tuple.append(indices[i][np.argmin(imb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb85783",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "# Full optimization\n",
    "plt.plot(range(1, len(lowimb)+1), lowimb, \"-o\", label=\"Full trajectory\", linewidth=1.5, color = \"tab:green\")\n",
    "\n",
    "plt.xlabel(\"Number of non-zero features\",fontsize=14)\n",
    "plt.ylabel(\"DII\")\n",
    "plt.ylim(0.05,0.5)\n",
    "plt.grid(visible=True, which='major', axis='both')\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(1,11), fontsize=11)\n",
    "plt.yticks(np.arange(0.1,0.5,0.05), fontsize=11)\n",
    "plt.minorticks_off()\n",
    "plt.tick_params(axis='both', which='major', width=0.176)\n",
    "plt.grid(visible=False)\n",
    "plt.grid(visible=True, which='major', axis='y', linestyle=':', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features leading to the lowest imbalances\n",
    "lowimb_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a80407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relative weights of the above features\n",
    "lowimb_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d671e",
   "metadata": {},
   "source": [
    "### plot the optimization of the best 5plet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the optimization for the best 5plet\n",
    "tups = 4 # best 5 plet\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(imbalances_opt[tups][lowimb_index[tups]], color=\"tab:cyan\")\n",
    "plt.xticks([0,40,80])\n",
    "plt.yticks([0.181,0.179]) #5\n",
    "plt.ylim((0.1785,0.1815))   #5\n",
    "plt.ylabel(\"DII\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.minorticks_off()\n",
    "plt.tick_params(axis='y', which='minor', width=0.176)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b131149",
   "metadata": {},
   "source": [
    "# Block transferability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477324ab",
   "metadata": {},
   "source": [
    "### Divide data into 4 blocks of 10000 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_data = []\n",
    "blocked_groundtruth = []\n",
    "blocksize = inputs_classic.shape[0]//4\n",
    "print(\"blocksize: \",blocksize)\n",
    "for j in range(4):\n",
    "    print(\"block \", j)\n",
    "    data_cut = inputs_classic[(j*blocksize):((j+1)*blocksize)] # consecutive blocks\n",
    "    dis = dist[(j*blocksize):((j+1)*blocksize)]\n",
    "    blocked_data.append(data_cut)\n",
    "    blocked_groundtruth.append(dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db69566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if these blocks are subsampled by 7, we get samples of 1428 points, (almost) like the above optimized 1429\n",
    "10000//7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2bc83",
   "metadata": {},
   "source": [
    "### Load/Calculate the training set \n",
    "- Optimize DII and weights for each block section\n",
    "- Each block is subsampled into 7 sections, such that each section has 1428 points\n",
    "- The below calculation takes a full day on an average workstation. Uncomment, if you wish to calculate. Otherwise run the cells in order as they are, to use our precalculated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imb_opt_listb=[]\n",
    "# gamma_opt_listb=[]\n",
    "\n",
    "# for b in range(len(blocked_data)):\n",
    "#     print(\"Block \", b, \" optimization\")\n",
    "#     ins_classic = blocked_data[b][::7] # Use every 7th point to be sure to decorrelate\n",
    "#     dis = blocked_groundtruth[b][::7]\n",
    "\n",
    "#     imbalances_opt=[]\n",
    "#     gammas_opt = []\n",
    "#     #for j in range(len(indices)):\n",
    "#     for j in range(0, len(indices)):\n",
    "#         imb=[]\n",
    "#         gams=[]\n",
    "#         print(\"for \", j+1, \" CVs there are \", len(indices[j]), \" combinations\")\n",
    "#         for i in indices[j]:\n",
    "#             print(\"optimizing combi \", i, \" for \", j+1, \" CVs\" )   \n",
    "#             target_object = FeatureWeighting(dis)\n",
    "#             inputs_object = FeatureWeighting(ins_classic[:,i])\n",
    "#             w = inputs_object.return_weights_optimize_dii(\n",
    "#                 target_data = target_object,\n",
    "#                 n_epochs = 80,\n",
    "#                 constrain = False,\n",
    "#                 initial_weights = None,\n",
    "#                 lambd = None,\n",
    "#                 learning_rate = None,\n",
    "#                 l1_penalty = 0.0,\n",
    "#                 decaying_lr = \"exp\"\n",
    "#             )\n",
    "#             dii = inputs_object.history[\"dii_per_epoch\"]\n",
    "#             weights = inputs_object.history[\"weights_per_epoch\"]\n",
    "#             imb.append(dii)\n",
    "#             gams.append(weights)\n",
    "#         imbalances_opt.append(imb)\n",
    "#         gammas_opt.append(gams)\n",
    "#     imb_opt_listb.append(imbalances_opt)\n",
    "#     gamma_opt_listb.append(gammas_opt)\n",
    "\n",
    "# # np.save('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/imbalances_opt.npy', np.array(imb_opt_listb, dtype=object))\n",
    "# # np.save('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/gammas_opt.npy', np.array(gamma_opt_listb, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_opt_listb = np.load('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/imbalances_opt.npy',allow_pickle=True)\n",
    "gamma_opt_listb = np.load('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/gammas_opt.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9603f34",
   "metadata": {},
   "source": [
    "#### Select best training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out for each optimization run the lowest imbalance during the epochs, and the according weights (gammas)\n",
    "imbalances_opt_end_listb = []\n",
    "gammas_opt_end_listb = []\n",
    "for k, imbalances_opt in enumerate(imb_opt_listb):\n",
    "    imbalances_opt_end = []\n",
    "    gammas_opt_end = []\n",
    "    gammas_opt=gamma_opt_listb[k]\n",
    "    for i, imbi in enumerate(imbalances_opt):\n",
    "        imb = []\n",
    "        gamm = []\n",
    "        for jj, j in enumerate(imbi):\n",
    "            #imb.append(j[-1])\n",
    "            imb.append(np.nanmin(j))\n",
    "            gamm.append(gammas_opt[i][jj][np.nanargmin(j)])\n",
    "        imbalances_opt_end.append(imb)\n",
    "        gammas_opt_end.append(gamm)\n",
    "    imbalances_opt_end_listb.append(imbalances_opt_end)\n",
    "    gammas_opt_end_listb.append(gammas_opt_end)\n",
    "    \n",
    "# now pick out from all the singlets, duplets, etc the lowest one, and according gamma\n",
    "lowimb_listb=[]\n",
    "lowimb_index_listb=[]\n",
    "lowimb_gamma_listb = []\n",
    "lowimb_tuple_listb = []\n",
    "for j, imbalances_opt_end in enumerate(imbalances_opt_end_listb):\n",
    "    gammas_opt_end = gammas_opt_end_listb[j]\n",
    "    lowimbb = []\n",
    "    lowimb_indexb = []\n",
    "    lowimb_gammab = []\n",
    "    lowimb_tupleb = []\n",
    "    for i, imb in enumerate(imbalances_opt_end):\n",
    "        lowimbb.append(np.min(imb))\n",
    "        lowimb_indexb.append(np.argmin(imb))\n",
    "        lowimb_gammab.append(gammas_opt_end[i][np.argmin(imb)])\n",
    "        lowimb_tupleb.append(indices[i][np.argmin(imb)])\n",
    "    lowimb_listb.append(lowimbb)\n",
    "    lowimb_index_listb.append(lowimb_indexb)\n",
    "    lowimb_gamma_listb.append(lowimb_gammab)\n",
    "    lowimb_tuple_listb.append(lowimb_tupleb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0977a3",
   "metadata": {},
   "source": [
    "### Load/Calculate the test imbalances: \n",
    "- Use the feature tuples generated in the training blocks\n",
    "- Apply to test block sections\n",
    "- running this takes roughly 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test set of blocks\n",
    "\n",
    "# imbalances_test_list=[]\n",
    "# all_blocks=[0,1,2,3]\n",
    "# for trainblock in range(4):\n",
    "#     print(\"analysis assiciated to training block \", trainblock+1)\n",
    "#     mytestblocks = np.delete(all_blocks, trainblock)\n",
    "#     imbalances_test3=[]\n",
    "#     for j in mytestblocks:\n",
    "#         print(\"start running test block \", j+1)\n",
    "#         data_cut_ = blocked_data[j] # consecutive blocks\n",
    "#         dis_ = blocked_groundtruth[j]\n",
    "#         for k in range(7): #take every 7ths point\n",
    "#             print(\"start running section \", (k+1))\n",
    "#             data_cut = data_cut_[k::7]\n",
    "#             dis = dis_[k::7]\n",
    "#             target_B = FeatureWeighting(dis)\n",
    "#             imb = []\n",
    "#             for i, tupl in enumerate(lowimb_tuple_listb[trainblock]):  # take the tuple optimized in the training block\n",
    "#                 data = data_cut[:,tupl] * lowimb_gamma_listb[trainblock][i] # take the weights optimized in the training block\n",
    "#                 input_A = FeatureWeighting(data)\n",
    "#                 im = input_A.return_dii(target_data = target_B, lambd=None)\n",
    "#                 imb.append(im)\n",
    "#             imbalances_test3.append(imb)\n",
    "#     imbalances_test_list.append(imbalances_test3)\n",
    "    \n",
    "# # np.save('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/imbalances_test.npy',imbalances_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72586dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalances_test_list = np.load('./ANALYSIS/FULL_COMBINATORICS_BLOCK_CROSS_VAL/imbalances_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d845e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "# Block analysis: Training\n",
    "plt.errorbar(range(1,11), np.mean(np.array(lowimb_listb),axis=0), np.std(np.array(lowimb_listb),axis=0), marker=\".\", linewidth=1.5, label=\"Training blocks\")\n",
    "\n",
    "# Full optimization\n",
    "plt.plot(range(1, len(lowimb)+1), lowimb, \"-o\", label=\"Full trajectory\", linewidth=1.5, color = \"tab:green\")\n",
    "\n",
    "#Block analysis: Test\n",
    "plt.errorbar(range(1,11), np.mean(imbalances_test_list,axis=(0,1)), np.std(imbalances_test_list,axis=(0,1)), color=\"orange\", linestyle='--', marker='.', linewidth=1.5, label=\"Test blocks\", zorder=8)\n",
    "\n",
    "plt.title(\"Blocked cross validation\",fontsize=14)\n",
    "plt.xlabel(\"Number of non-zero features\",fontsize=14)\n",
    "plt.ylabel(\"DII\")\n",
    "plt.ylim(0.05,0.5)\n",
    "plt.grid(visible=True, which='major', axis='both')\n",
    "plt.legend(title=\"Average and st.dev.\", fontsize=12, title_fontsize=12)\n",
    "plt.xticks(range(1,11), fontsize=11)\n",
    "plt.yticks(np.arange(0.1,0.5,0.05), fontsize=11)\n",
    "plt.minorticks_off()\n",
    "plt.tick_params(axis='both', which='major', width=0.176)\n",
    "plt.grid(visible=False)\n",
    "plt.grid(visible=True, which='major', axis='y', linestyle=':', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b09f6",
   "metadata": {},
   "source": [
    "# Find the free energy clusters in the full space and the space of the best 3 features\n",
    "- It is possible to use the stored values for \"best3\" and \"dis\" or load them by uncommenting below cell, if this section is run independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and save the best 3 variables\n",
    "ins_classic = inputs_classic[::28]\n",
    "best3 = ins_classic[:,lowimb_tuple[2]]*lowimb_gamma[2]\n",
    "dis = dist[::28]\n",
    "\n",
    "# np.savetxt('./FREE_ENERGY_CLUSTER/best3_scaled_rgyr_pc1_pc2_1429pt.npy', best3)\n",
    "# np.save('./FREE_ENERGY_CLUSTER/dis_1429pt.npy', dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best3 = np.load('./FREE_ENERGY_CLUSTER/best3_scaled_rgyr_pc1_pc2_1429pt.npy')\n",
    "# dis = np.load('./FREE_ENERGY_CLUSTER/dis_1429pt.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4028d",
   "metadata": {},
   "source": [
    "## Best 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed6fa8",
   "metadata": {},
   "source": [
    "### Intrinsic dimension and clustering in the space of the best 3 with DADApy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dadapy import Data\n",
    "from dadapy import plot as pl\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from skimage import measure\n",
    "from scipy.interpolate import griddata, Rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a Data object\n",
    "d_best3 = Data(best3, verbose=False)\n",
    "# compute distances by setting the correct period\n",
    "d_best3.compute_distances(maxk=min(best3.shape[0]-1, 10000))\n",
    "# estimate the intrinsic dimension\n",
    "d_best3.compute_id_2NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic dimension scaling analysig using two different methods\n",
    "ids_2nn, errs_2nn, scales_2nn = d_best3.return_id_scaling_2NN()\n",
    "ids_gride, errs_gride, scales_gride = d_best3.return_id_scaling_gride(range_max=1024)\n",
    "\n",
    "col = 'darkorange'\n",
    "plt.plot(scales_2nn, ids_2nn, alpha=0.85)\n",
    "plt.errorbar(scales_2nn, ids_2nn, errs_2nn, fmt='None')\n",
    "plt.scatter(scales_2nn, ids_2nn, edgecolors='k',s=50,label='2nn decimation')\n",
    "plt.plot(scales_gride, ids_gride, alpha=0.85, color=col)\n",
    "plt.errorbar(scales_gride, ids_gride, errs_gride, fmt='None',color=col)\n",
    "plt.scatter(scales_gride, ids_gride, edgecolors='k',color=col,s=50,label='2nn gride')\n",
    "plt.xlabel(r'Scale',size=15)\n",
    "plt.ylabel('Estimated ID',size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.legend(frameon=False,fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaebd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate density via PAk\n",
    "d_best3.set_id(3.)\n",
    "d_best3.compute_density_PAk()\n",
    "\n",
    "# cluster data via Advanced Density Peak\n",
    "d_best3.compute_clustering_ADP(Z=2.0,halo=False);\n",
    "n_clusters = len(d_best3.cluster_centers)\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.get_dendrogram(d_best3, cmap='Set2', logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster populations\n",
    "populations = [ len(el) for r_,el in enumerate(d_best3.cluster_indices)]\n",
    "print(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34173423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centers. In the original trajecotory these frames are given by (center + 400) * 10\n",
    "print(d_best3.cluster_centers)\n",
    "print(\"For the trajectory use frames: \",np.array(d_best3.cluster_centers)*28 + 1580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the RGYR, PC1, PC2 value of the cluster center of beta pin and loop?\n",
    "print(best3[196])\n",
    "print(best3[942])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Free energy\n",
    "W = - d_best3.log_den \n",
    "#np.savetxt('./FREE_ENERGY_CLUSTER/MATLAB/best3_free_energy_1429pt.txt', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc9b39",
   "metadata": {},
   "source": [
    "#### For making a isosurface (in Free Energy) rendering in Matlab, map the data to a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map my values to a uniform, ordered grid!\n",
    "\n",
    "X = best3[:,0] #RGYR\n",
    "Y = best3[:,1] #PC1\n",
    "Z = best3[:,2] #PC2\n",
    "W = - d_best3.log_den #Free energy\n",
    "\n",
    "## make regular grid to use below with marching cubes instead of Matlab\n",
    "XX,YY,ZZ = np.mgrid[X.min():X.max():110j, Y.min():Y.max():110j, Z.min():Z.max():110j]\n",
    "newdata = griddata( best3, W, (XX,YY,ZZ) , method='linear', rescale=True)\n",
    "\n",
    "mygrid = np.concatenate((XX.flatten()[:,np.newaxis], YY.flatten()[:,np.newaxis], ZZ.flatten()[:,np.newaxis], newdata.flatten()[:,np.newaxis]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bf8ad3",
   "metadata": {},
   "source": [
    "#### The publication image was rendered in matlab. Below an alternative rendering\n",
    "The matlab script is in folder FREE_ENERGY_CLUSTER/MATLAB as \"matlab_free_energy_plot_script\" and below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d414f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR MATLAB\n",
    "\n",
    "# close all\n",
    "# clear all\n",
    "# hold off\n",
    "# NGRID=130;\n",
    "# xx=load('../best3_scaled_rgyr_pc1_pc2_1429pt.txt');\n",
    "# ff=load('./best3_free_energy_1429pt.txt');\n",
    "# x=xx(:,1);\n",
    "# y=xx(:,2);\n",
    "# z=xx(:,3);\n",
    "# [minx,maxx] = bounds(x);\n",
    "# [miny,maxy] = bounds(y);\n",
    "# [minz,maxz] = bounds(z);\n",
    "# [xq,yq,zq] = meshgrid(linspace(minx,maxx,NGRID),linspace(miny,maxy,NGRID),linspace(minz,maxz,NGRID));\n",
    "# f=ff(:,1)*2.479;\n",
    "# fq = griddata(x,y,z,f,xq,yq,zq,'natural');\n",
    "# patch(isosurface(xq,zq,yq,fq, 9.),'FaceColor','red','FaceAlpha',0.1,'EdgeColor','none');\n",
    "# patch(isosurface(xq,zq,yq,fq, 4.),'FaceColor','blue','FaceAlpha',0.3,'EdgeColor','none');\n",
    "# patch(isosurface(xq,zq,yq,fq, -0.25),'FaceColor','blue','FaceAlpha',1.,'EdgeColor','none');\n",
    "# camlight;\n",
    "# campos([-15.2,-17.8,10.8]);\n",
    "# view(-52.3,22.7);\n",
    "# camtarget([7.8,-0.049,0.104]);\n",
    "# camup([0 0 1]);\n",
    "# camva(9.66);\n",
    "# light(\"Style\",\"local\",\"Position\",[-17,-29,15]);\n",
    "# xlabel('RGYR'); ylabel('PC2'); zlabel('PC1');\n",
    "# grid on;\n",
    "# set(gca,'FontName','Helvetica','FontSize',12);\n",
    "# lgd = legend(' 9.0 kJ/mol',' 4.0 kJ/mol','-0.25 kJ/mol');\n",
    "# title(lgd,'Free energy')\n",
    "# lighting gouraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use marching cubes to obtain the surface mesh of these ellipsoids\n",
    "verts, faces, normals, values = measure.marching_cubes(newdata, 0)\n",
    "verts2, faces2, normals2, values2 = measure.marching_cubes(newdata, 2)\n",
    "verts3, faces3, normals3, values3 = measure.marching_cubes(newdata, 5)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "mesh2 = Poly3DCollection(verts2[faces2])\n",
    "mesh2.set(facecolor='r', alpha=0.3)\n",
    "ax.add_collection3d(mesh2)\n",
    "\n",
    "mesh3 = Poly3DCollection(verts3[faces3])\n",
    "mesh3.set(alpha = 0.2)\n",
    "ax.add_collection3d(mesh3)\n",
    "\n",
    "mesh = Poly3DCollection(verts[faces])\n",
    "\n",
    "mesh.set(facecolor='r', alpha=0.6)\n",
    "ax.add_collection3d(mesh)\n",
    "ax.set_xlabel(\"RGYR\")\n",
    "ax.set_ylabel(\"PC1\")\n",
    "ax.set_zlabel(\"PC2\")\n",
    "ax.set_xlim(0,80)  # a = 6 (times two for 2nd ellipsoid)\n",
    "ax.set_ylim(0,80)  # b = 10\n",
    "ax.set_zlim(0,80)  # c = 16\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235a35b",
   "metadata": {},
   "source": [
    "## All heavy atom distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910791f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_atom_distances = dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c311f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_distances = Data(heavy_atom_distances,verbose=False)\n",
    "d_distances.compute_distances(maxk=min(heavy_atom_distances.shape[0]-1,10000))\n",
    "d_distances.compute_id_2NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID scaling analysig using two different methods\n",
    "ids_2nn, errs_2nn, scales_2nn = d_distances.return_id_scaling_2NN()\n",
    "ids_gride, errs_gride, scales_gride = d_distances.return_id_scaling_gride(range_max=1024)\n",
    "\n",
    "col = 'darkorange'\n",
    "plt.plot(scales_2nn, ids_2nn, alpha=0.85)\n",
    "plt.errorbar(scales_2nn, ids_2nn, errs_2nn, fmt='None')\n",
    "plt.scatter(scales_2nn, ids_2nn, edgecolors='k',s=50,label='2nn decimation')\n",
    "plt.plot(scales_gride, ids_gride, alpha=0.85, color=col)\n",
    "plt.errorbar(scales_gride, ids_gride, errs_gride, fmt='None',color=col)\n",
    "plt.scatter(scales_gride, ids_gride, edgecolors='k',color=col,s=50,label='2nn gride')\n",
    "plt.xlabel(r'Scale',size=15)\n",
    "plt.ylabel('Estimated ID',size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.legend(frameon=False,fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29118fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate density via PAk\n",
    "d_distances.set_id(8.)\n",
    "d_distances.compute_density_PAk()\n",
    "# cluster data via Advanced Density Peak\n",
    "d_distances.compute_clustering_ADP(Z=2.6,halo=False);\n",
    "n_clusters = len(d_distances.cluster_centers)\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.get_dendrogram(d_distances, cmap='Set2', logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster populations\n",
    "populations = [ len(el) for r_,el in enumerate(d_distances.cluster_indices)]\n",
    "print(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centers: In original trajecotory: (center + 400) * 10\n",
    "print(d_distances.cluster_centers)\n",
    "print(\"For the trajectory use frames: \",np.array(d_distances.cluster_centers)*28 + 1580)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f88ec",
   "metadata": {},
   "source": [
    "## Check equivalence of the two data descriptions\n",
    "- The cluster indices are not aligned from the two represebtations and have to be aligned until purity is maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3144e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation of cluster assignment: 2 -> 1 and 1 -> 2\n",
    "distances_cluster_assignments_2 = np.copy(d_distances.cluster_assignment)\n",
    "\n",
    "zeros = np.where(d_distances.cluster_assignment == 0)\n",
    "ones = np.where(d_distances.cluster_assignment == 1)\n",
    "twos = np.where(d_distances.cluster_assignment == 2)\n",
    "threes = np.where(d_distances.cluster_assignment == 3)\n",
    "\n",
    "\n",
    "distances_cluster_assignments_2[threes] = 0\n",
    "distances_cluster_assignments_2[zeros] = 2\n",
    "distances_cluster_assignments_2[twos] = 1\n",
    "distances_cluster_assignments_2[ones] = 0\n",
    "# number of elements in common after permutation\n",
    "print(\"purity beta-loop cluster\", sum(distances_cluster_assignments_2 == d_best3.cluster_assignment)/d_best3.N)\n",
    "print(\"purity intermediate cluster\", len(set(list(np.where(d_best3.cluster_assignment == 0)[0])).intersection(np.where(distances_cluster_assignments_2 == 0)[0]))/len(np.where(distances_cluster_assignments_2 == 0)[0]))\n",
    "print(\"purity collapsed loop cluster\", len(set(list(np.where(d_best3.cluster_assignment == 2)[0])).intersection(np.where(distances_cluster_assignments_2 == 2)[0]))/len(np.where(distances_cluster_assignments_2 == 2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88aa19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
